{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import win32gui\n",
    "import time\n",
    "from pynput.mouse import Controller\n",
    "import random\n",
    "\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "sys.path.append('..')\n",
    "from utilitaire.imgAiTrainer.imgAiTrainer import Trainer\n",
    "\n",
    "tr = Trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les fonctions pour cliquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction qui retourne un tuple contenant les positions de la fenêtre du jeu\n",
    "def position():\n",
    "    #récupère \"l'identifiant\" de la fenêtre nommée osu!\n",
    "    window_handle = win32gui.FindWindow(None, \"osu!\")\n",
    "    #si l'indentifiant est différent de 0 (si 0 il n'existe pas) et que la classe de la fenêtre est une application (car peut être une autre fenêtre nommée osu!)\n",
    "    if window_handle!=0 and win32gui.GetClassName(window_handle)[0:28] == \"WindowsForms10.Window.2b.app\":\n",
    "        #retourne la position de la fenêtre et 0 comme code de retour\n",
    "        return win32gui.GetWindowRect(window_handle),0\n",
    "    #sinon retourne les coordonnée innexactes et -1 en code d'erreur\n",
    "    return win32gui.GetWindowRect(window_handle),-1\n",
    "\n",
    "#fonction de vérification de position de la souris x,y -> Position du curseur / xF_g,yF_g -> position en haut à gauche de la fenêtre / xF_d,yF_d -> position en bas à droite de la fenêtre\n",
    "def isSortie(x,y):\n",
    "    #Si le curseur est sorti de la fenêtre je return False sinon je return True\n",
    "    return x < 0 or x > 800 or y < 0 or y > 600\n",
    "\n",
    "#fonction qui traduit les coordonnée relative à la fenêtre en coordonnée relative à l'écran\n",
    "def viser(xF_g,yF_d,xV,yV):\n",
    "        return xV+xF_g+2,yV+yF_d\n",
    "\n",
    "#fonction de clique\n",
    "def cliquer():\n",
    "    if isClic:\n",
    "        souris.release(Button.left)\n",
    "        isClic = False\n",
    "    else :\n",
    "        souris.press(Button.left)\n",
    "        isClic = True\n",
    "\n",
    "#fonction clic\n",
    "def clic(x,y):\n",
    "    \n",
    "    cliquer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour retourner le score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupScore():\n",
    "    return;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IA Cercle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (600,800,3)\n",
    "\n",
    "modelCercle = keras.models.Sequential()\n",
    "modelCercle.add(keras.layers.Convolution2D(32, 5, 5, padding='same',  activation='relu', input_shape=img_shape))\n",
    "modelCercle.add(keras.layers.Convolution2D(64, 5, 5, padding='same',  activation='relu'))\n",
    "modelCercle.add(keras.layers.Convolution2D(128, 5, 5, padding='same',  activation='relu'))\n",
    "modelCercle.add(keras.layers.Flatten())\n",
    "modelCercle.add(keras.layers.Dense(100, activation='relu'))\n",
    "modelCercle.add(keras.layers.Dense(4, activation='linear'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "modelCercle.compile(optimizer=opt,loss='mean_squared_error')\n",
    "\n",
    "modelCercle.load_weights('save/Cercle/model')\n",
    "\n",
    "def recupCercle():\n",
    "    imgGrayIa=recupImage();\n",
    "    y_pred = modelCercle.predict(imgGrayIa)\n",
    "    return y_pred;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSU!Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-8346bb176e45>:5: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "#Creation du model pour clic\n",
    "#batchshape: ensemble; ici: ensemble de taille indéerminé avec chacune 3 valeur (x,y,difference entre rayon)\n",
    "Input = tf.keras.Input([None, 1]);\n",
    "\n",
    "layer = tf.keras.layers.Dense(8, 'relu',True).apply(Input);\n",
    "#3 neuronnes de sortis: clic:oui ou non\n",
    "#linéaire car on aura un espérence du nombre de récompense.\n",
    "output = tf.keras.layers.Dense(1, 'linear',True).apply(layer);\n",
    "modelClic = tf.keras.Model(Input, output);\n",
    "model_optimizer = tf.keras.optimizers.Adam(0.01);\n",
    "\n",
    "        \n",
    "def model_loss(tf_states, tf_actions, Qtargets):\n",
    "                return modelClic.predict(tf_states).sub(Qtargets).square().mul(tf_actions).mean();\n",
    "\n",
    "\n",
    "#Choix si greed ou explore.\n",
    "def pickActionClic(st, eps):\n",
    "    st_tensor = tf.Tensor([st]);\n",
    "    if (Math.random() < eps): # Pick a random action\n",
    "            act = [random.randint(0,1)];\n",
    "    else:\n",
    "        result = modelClic.predict(st_tensor); #predis les possibilitées\n",
    "        argmax = result.argMax(1); #récup le chemin avec le meilleur résultat.\n",
    "        act = argmax.buffer().values[0];\n",
    "        argmax.dispose();\n",
    "        result.dispose();\n",
    "    st_tensor.dispose();\n",
    "    return act;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickAction(st,eps):\n",
    "    act=pickActionClic(st,eps)\n",
    "    act+=[st[0],st[1]] #ajout de x et y; à modifier\n",
    "    return act;\n",
    "\n",
    "def doAction(act):\n",
    "    if(act[0]==1):\n",
    "        cliquer(act[1],act[2])\n",
    "    score=getScore()\n",
    "    return score;\n",
    "\n",
    "def train_model(states,actions,rewards,model):\n",
    "    size=len(states)\n",
    "    \n",
    "    #Transformer les listes en tensor\n",
    "    tf_states=tf.Tensor(len(states), shape=[size,3])\n",
    "    tf_actions=tf.Tensor(len(actions), shape=[size,3])\n",
    "    tf_rewards=tf.Tensor(rewards, shape=[size,1])\n",
    "    \n",
    "    #Entrainement\n",
    "    batch_size=32\n",
    "    b=0\n",
    "    while b<batch_size:\n",
    "        if b + batch_size < size:\n",
    "            to=batch_size\n",
    "        else:\n",
    "            to=size+b\n",
    "        tf_states_b = tf_states[b: to]\n",
    "        tf_actions_b = tf_actions[b: to]\n",
    "        tf_rewards_b = tf_rewards[b: to]\n",
    "        \n",
    "        model_optimizer.minimize(model_loss(tf_states_b, tf_actions_b, tf_rewards_b))\n",
    "        \n",
    "        #Liberation mémoire\n",
    "        tf_states_b.dispose();\n",
    "        tf_actions_b.dispose();\n",
    "        tf_rewards_b.dispose();\n",
    "        \n",
    "        b+=32\n",
    "    \n",
    "    #Liberation mémoire\n",
    "    tf_states.dispose();\n",
    "    tf_actions.dispose();\n",
    "    tf_rewards.dispose();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recupImage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fd6f5a39f966>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecupCercle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-25f30f56f572>\u001b[0m in \u001b[0;36mrecupCercle\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrecupCercle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mimgGrayIa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecupImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelCercle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgGrayIa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recupImage' is not defined"
     ]
    }
   ],
   "source": [
    "#AlgoFinal\n",
    "\n",
    "st=[0,0,-1];\n",
    "eps=1 #100% exploration\n",
    "reward=0\n",
    "\n",
    "#Stockage experience\n",
    "actions=[0 for i in range(100)]\n",
    "rewards=[0 for i in range(100)]\n",
    "states=[0 for i in range(100)]\n",
    "next_state=[0 for i in range(100)]\n",
    "\n",
    "st=recupCercle();\n",
    "\n",
    "for i in range(100):\n",
    "    action=pickAction(st,eps);#appel IA\n",
    "    reward=doAction(action);#Fait l'action et récupère le nombre de points reçus\n",
    "    \n",
    "    st2=recupCercle();\n",
    "    \n",
    "    states[i]=st;\n",
    "    actions[i]=action;\n",
    "    rewards[i]=[reward];\n",
    "    \n",
    "    train_model(states,actions,rewards,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
