{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ceci est le fichier principal, pour l'instant il regroupe toutes les fonctions et le main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import win32gui\n",
    "import time\n",
    "from pynput.mouse import Controller\n",
    "import random\n",
    "\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageGrab\n",
    "sys.path.append('..')\n",
    "from utilitaire.imgAiTrainer.imgAiTrainer import Trainer\n",
    "\n",
    "tr = Trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions pour récupérer l'image du jeu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fonctions pour récupérer l'image du jeu\n",
    "#retourne la position de la fenêtre d'Osu\n",
    "def position():\n",
    "    window_handle = win32gui.FindWindow(None, \"osu!\")\n",
    "    if window_handle!=0 and win32gui.GetClassName(window_handle)[0:28] == \"WindowsForms10.Window.2b.app\":\n",
    "        return win32gui.GetWindowRect(window_handle),0\n",
    "    return win32gui.GetWindowRect(window_handle),-1\n",
    "\n",
    "#retourne l'image sous forme de matrice\n",
    "def Foncimg(x,y,x1,y1):\n",
    "    img = ImageGrab.grab(bbox=(x,y,x1,y1))\n",
    "    #img = img.resize((160, 120))\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "    imgIa = np.expand_dims(img, axis=0)\n",
    "    return imgIa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions pour l'IA supervisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2263b2a6250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fonction pour l'IA supervisée\n",
    "def show_sample(img):\n",
    "  figure, axis = plt.subplots(1,1)\n",
    "  axis.imshow(img)\n",
    "    \n",
    "def show_sample2(img,img2):\n",
    "  figure, (axis1, axis2) = plt.subplots(1,2)\n",
    "  axis1.imshow(img)\n",
    "  axis2.imshow(img2)\n",
    "\n",
    "#On charge les poids et le modèle entrainé\n",
    "model = keras.models.load_model('save/model/model')\n",
    "model.load_weights('save/poids/model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions pour l'IA par renforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-82ec00b62335>:5: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "#Creation du model pour clic\n",
    "#batchshape: ensemble; ici: ensemble de taille indéerminé avec chacune 3 valeur (x,y,difference entre rayon)\n",
    "Input = tf.keras.Input([None, 1])\n",
    "\n",
    "layer = tf.keras.layers.Dense(8, 'relu',True).apply(Input)\n",
    "#3 neuronnes de sortis: clic:oui ou non\n",
    "#linéaire car on aura un espérence du nombre de récompense.\n",
    "output = tf.keras.layers.Dense(1, 'linear',True).apply(layer)\n",
    "modelClic = tf.keras.Model(Input, output)\n",
    "model_optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "        \n",
    "def model_loss(tf_states, tf_actions, Qtargets):\n",
    "                return modelClic.predict(tf_states).sub(Qtargets).square().mul(tf_actions).mean()\n",
    "\n",
    "\n",
    "#Choix si greed ou explore.\n",
    "def pickActionClic(st, eps):\n",
    "    st_tensor = tf.Tensor([st])\n",
    "    if (Math.random() < eps): # Pick a random action\n",
    "            act = [random.randint(0,1)]\n",
    "    else:\n",
    "        result = modelClic.predict(st_tensor) #predis les possibilitées\n",
    "        argmax = result.argMax(1) #récup le chemin avec le meilleur résultat.\n",
    "        act = argmax.buffer().values[0]\n",
    "        argmax.dispose()\n",
    "        result.dispose()\n",
    "    st_tensor.dispose()\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickAction(st,eps):\n",
    "    act=pickActionClic(st,eps)\n",
    "    act+=[st[0],st[1]] #ajout de x et y; à modifier\n",
    "    return act\n",
    "\n",
    "def doAction(act):\n",
    "    if(act[0]==1):\n",
    "        cliquer(act[1],act[2])\n",
    "    score=getScore()\n",
    "    return score\n",
    "\n",
    "def train_model(states,actions,rewards,model):\n",
    "    size=len(states)\n",
    "    \n",
    "    #Transformer les listes en tensor\n",
    "    tf_states=tf.Tensor(len(states), shape=[size,3])\n",
    "    tf_actions=tf.Tensor(len(actions), shape=[size,3])\n",
    "    tf_rewards=tf.Tensor(rewards, shape=[size,1])\n",
    "    \n",
    "    #Entrainement\n",
    "    batch_size=32\n",
    "    b=0\n",
    "    while b<batch_size:\n",
    "        if b + batch_size < size:\n",
    "            to=batch_size\n",
    "        else:\n",
    "            to=size+b\n",
    "        tf_states_b = tf_states[b: to]\n",
    "        tf_actions_b = tf_actions[b: to]\n",
    "        tf_rewards_b = tf_rewards[b: to]\n",
    "        \n",
    "        model_optimizer.minimize(model_loss(tf_states_b, tf_actions_b, tf_rewards_b))\n",
    "        \n",
    "        #Liberation mémoire\n",
    "        tf_states_b.dispose()\n",
    "        tf_actions_b.dispose()\n",
    "        tf_rewards_b.dispose()\n",
    "        \n",
    "        b+=32\n",
    "    \n",
    "    #Liberation mémoire\n",
    "    tf_states.dispose()\n",
    "    tf_actions.dispose()\n",
    "    tf_rewards.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction pour obtenir la position du cercle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupPositionCercle():\n",
    "    #Onrécupère la position de la fenêtre d'osu, on considère qu'elle ne bougera pas,et que le jeu est en 800*600 fenêtré\n",
    "    posFenetre,isFenetre=position()\n",
    "    #On récupère l'image\n",
    "    print(posFenetre[3])\n",
    "    img=Foncimg(posFenetre[0],posFenetre[1],posFenetre[2],posFenetre[3])\n",
    "    #On obtient les prédiction de l'IA supervisée en un tableau\n",
    "    y_pred = model.predict(img)\n",
    "    #On return les données à la forme désirée\n",
    "    return [y_pred[0][0],y_pred[0][1],y_pred[0][3]-y_pred[0][2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n",
      "[159.41046, 157.02164, 35.659866]\n",
      "Wall time: 70.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "st=recupPositionCercle()\n",
    "print(st)\n",
    "\n",
    "#AlgoFinal\n",
    "\n",
    "#st=[0,0,-1]\n",
    "#eps=1 #100% exploration\n",
    "#reward=0\n",
    "\n",
    "#Stockage experience\n",
    "#actions=[0 for i in range(100)]\n",
    "#rewards=[0 for i in range(100)]\n",
    "#states=[0 for i in range(100)]\n",
    "#next_state=[0 for i in range(100)]\n",
    "\n",
    "#st=recupPositionCercle()\n",
    "\n",
    "#for i in range(100):\n",
    "#    action=pickAction(st,eps)#appel IA\n",
    "#    reward=doAction(action)#Fait l'action et récupère le nombre de points reçus\n",
    "    \n",
    "#    st2=recupPositionCercle()\n",
    "    \n",
    "#    states[i]=st\n",
    "#    actions[i]=action\n",
    "#    rewards[i]=[reward]\n",
    "    \n",
    "#    train_model(states,actions,rewards,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
